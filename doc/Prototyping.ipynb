{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osbrain\n",
    "from osbrain import run_nameserver\n",
    "from osbrain import run_agent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import blackboard\n",
    "import knowledge_agent as ka\n",
    "import time\n",
    "import train_surrogate_models as tm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Multi-Agent Blackbaord System\n",
    "\n",
    "We start by initializing our multi-agent system using osBrain.\n",
    "For the basic program, three agents will be required.\n",
    "\n",
    "* Agent 1: Blackboard\n",
    "* Agent 2: Knowledge Agent - Neutronics\n",
    "* Agent 3: Knowledge Agent - Blackboard checker\n",
    "\n",
    "The blackboard agent will retain all of the optimization results obtained by the neutronics agent on the third level of the blackboard.\n",
    "Abstract level 3 contains raw data in the form of Pandas Dataframe. \n",
    "This data consists of the design variables (height, smear, and plutonium fraction), objectives (keff, void coefficient, doppler coefficient, plutonium fraction), and the weights for each objective.\n",
    "\n",
    "The neutronics knowledge agent (KA) will run a neutronics optimization for a given set of objective weights.\n",
    "This is performed using Dakota as the optimization engine, and a surrogate model to obtain the reactor paramters (i.e. our objective functions).\n",
    "Once an optimal solution has been determined, the neutronics KA writes the associated design variables, objective functions, and weights to the blackboard.\n",
    "\n",
    "The blackboard checker KA examines abstract level 3 of the blackboard to determine if solutions are close to the desired solution.\n",
    "If a solution is within some percent of the desired solution, the blackboard check KA will take basic information from abstract level 3 and place it in abstract level 2.\n",
    "\n",
    "We start off by simply initializing the blackboard and neutronics KA.\n",
    "This will allow us to see how the Dakota interface operates, and will run 5 Dakota optimizations for five different weighting schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast server running on 0.0.0.0:9091\n",
      "NS running on 127.0.0.1:18250 (127.0.0.1)\n",
      "URI = PYRO:Pyro.NameServer@127.0.0.1:18250\n",
      "Examining Reactor: Core_0_0_0_0\n",
      "Examining Reactor: Core_1_0_0_0\n",
      "Examining Reactor: Core_0_0_1_0\n",
      "Examining Reactor: Core_0_1_0_0\n",
      "Examining Reactor: Core_0_0_0_1\n",
      "NS shut down.\n"
     ]
    }
   ],
   "source": [
    "ns = run_nameserver()\n",
    "bb = run_agent(name='blackboard', base=blackboard.Blackboard)\n",
    "ka_rp = run_agent(name='ka_rp', base=ka.KaReactorPhysics_Proxy)\n",
    "ka_rp.add_blackboard(bb)\n",
    "ka_rp.connect_REP_blackboard()\n",
    "\n",
    "ka_rp.objectives = ['keff', 'void_coeff', 'doppler_coeff', 'pu_content']\n",
    "ka_rp.design_variables = ['height', 'smear', 'pu_content']\n",
    "ka_rp.results_path = '/Users/ryanstewart/projects/Dakota_Interface/GA/mabs_results/'\n",
    "\n",
    "lists = {'a': [0,0,0,0], 'w': [1,0,0,0], 'x': [0,0,1,0], 'y': [0,1,0,0], 'z': [0,0,0,1]}\n",
    "for wl in lists.values():\n",
    "    print('Examining Reactor: Core_{}_{}_{}_{}'.format(wl[0],wl[1],wl[2],wl[3]))\n",
    "    ka_rp.set_attr(weights=wl)\n",
    "    ka_rp.run_dakota_proxy()\n",
    "    ka_rp.read_dakota_results()\n",
    "    ka_rp.write_to_blackboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction \n",
    "\n",
    "The previous cell built and ran 5 different Dakota optimization runs to examine the effects that the weighting scheme has on the objectives.\n",
    "The neutronics KA obtained this informatin using a surrogate model to perform the optimization proces.\n",
    "Results were then written to the blackboard, where they can easily be examined.\n",
    "Below we print out the optimized design variables along with the associated objective functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactor: core_0000 \n",
      " Height: 79.8 Smear: 67.05 Pu: 0.6025 \n",
      " keff: 1.1702 Void: -64.89  Doppler: -0.4401 \n",
      " Weights : (0,0,0,0)\n",
      "Reactor: core_1000 \n",
      " Height: 78.95 Smear: 67.25 Pu: 0.9175 \n",
      " keff: 1.2474 Void: -35.97  Doppler: -0.3506 \n",
      " Weights : (1,0,0,0)\n",
      "Reactor: core_0010 \n",
      " Height: 51.7 Smear: 50.65 Pu: 0.14 \n",
      " keff: 0.7944 Void: -196.49  Doppler: -0.9912 \n",
      " Weights : (0,0,1,0)\n",
      "Reactor: core_0100 \n",
      " Height: 51.2 Smear: 50.75 Pu: 0.0575 \n",
      " keff: 0.7721 Void: -204.77  Doppler: -1.0157 \n",
      " Weights : (0,1,0,0)\n",
      "Reactor: core_0001 \n",
      " Height: 67.15 Smear: 57.0 Pu: 0.0025 \n",
      " keff: 0.8809 Void: -168.29  Doppler: -0.8457 \n",
      " Weights : (0,0,0,1)\n"
     ]
    }
   ],
   "source": [
    "lvl_3 = bb.get_attr('lvl_3')\n",
    "for k,v in lvl_3.items():\n",
    "    print('Reactor: {} \\n Height: {} Smear: {} Pu: {} \\n keff: {} Void: {}  Doppler: {} \\n Weights : ({},{},{},{})'.format(k, \n",
    "        v['reactor_parameters']['height'][k], v['reactor_parameters']['smear'][k], v['reactor_parameters']['pu_content'][k], round(v['reactor_parameters']['keff'][k],4), round(v['reactor_parameters']['void'][k],2), round(v['reactor_parameters']['Doppler'][k],4),\n",
    "        v['reactor_parameters']['w_keff'][k],v['reactor_parameters']['w_void'][k],v['reactor_parameters']['w_dopp'][k],v['reactor_parameters']['w_pu'][k],))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining Reactor: Core_1_1_1_1\n",
      "Examining Reactor: Core_1_2_2_2\n",
      "Examining Reactor: Core_2_1_1_1\n",
      "Examining Reactor: Core_3_1_1_1\n",
      "Examining Reactor: Core_3_2_1_1\n",
      "Examining Reactor: Core_0.5_0.2_0.1_2\n",
      "Examining Reactor: Core_0.4_0.1_0.2_0.3\n",
      "Examining Reactor: Core_0.6_0.2_0.1_0.1\n",
      "Examining Reactor: Core_0.3_0.3_0.3_0.1\n",
      "Examining Reactor: Core_3_2_1_1\n"
     ]
    }
   ],
   "source": [
    "lists = {'a': [1,1,1,1], 'w': [1,2,2,2], 'x': [2,1,1,1], 'y': [3,1,1,1], 'z': [3,2,1,1],\n",
    "         'b': [0.5,0.2,0.1,2], 'c': [0.4,0.1,0.2,0.3], 'd': [0.6,0.2,0.1,0.1], 'e': [0.3,0.3,0.3,0.1], 'f': [3,2,1,1]}\n",
    "for wl in lists.values():\n",
    "    print('Examining Reactor: Core_{}_{}_{}_{}'.format(wl[0],wl[1],wl[2],wl[3]))\n",
    "    ka_rp.set_attr(weights=wl)\n",
    "    ka_rp.run_dakota_proxy()\n",
    "    ka_rp.read_dakota_results()\n",
    "    ka_rp.write_to_blackboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining Reactor: Core_8.0707_9.5284_3.4966_2.7676\n",
      "Examining Reactor: Core_2.5585_1.8056_7.5348_5.4819\n",
      "Examining Reactor: Core_2.6661_7.6023_9.5919_3.1685\n",
      "Examining Reactor: Core_5.5613_9.9184_3.9322_5.1531\n",
      "Examining Reactor: Core_3.8562_2.1938_0.6832_2.7551\n",
      "Examining Reactor: Core_5.6895_9.6485_7.0977_6.6008\n",
      "Examining Reactor: Core_5.9168_4.6631_0.6357_4.0691\n",
      "Examining Reactor: Core_6.9784_4.2185_1.1668_6.4702\n",
      "Examining Reactor: Core_8.0338_7.9_8.273_4.3106\n",
      "Examining Reactor: Core_6.2128_3.0202_5.1883_4.7563\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    wl = [round(10*random.random(),4) for i in range(4)]\n",
    "    print('Examining Reactor: Core_{}_{}_{}_{}'.format(wl[0],wl[1],wl[2],wl[3]))\n",
    "    ka_rp.set_attr(weights=wl)\n",
    "    ka_rp.run_dakota_proxy()\n",
    "    ka_rp.read_dakota_results()\n",
    "    ka_rp.write_to_blackboard()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7725662865705842\n",
      "106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0.94305477, -145.46843639,   -0.76456695,    0.20273155]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ka_rp.set_attr(weights=[1.15,1,1,1])\n",
    "ka_rp.run_dakota_proxy()\n",
    "ka_rp.read_dakota_results()\n",
    "ka_rp.write_to_blackboard()  \n",
    "temp_des = []\n",
    "temp_obj = []\n",
    "lvl_3 = bb.get_attr('lvl_3')\n",
    "print(lvl_3['core_1.5111']['reactor_parameters']['keff']['core_1.5111'])\n",
    "for k,v in lvl_3.items():\n",
    "    temp_des.append((v['reactor_parameters']['w_keff'][k],v['reactor_parameters']['w_void'][k],v['reactor_parameters']['w_dopp'][k],v['reactor_parameters']['w_pu'][k]))\n",
    "    temp_obj.append((v['reactor_parameters']['keff'][k],v['reactor_parameters']['void'][k],v['reactor_parameters']['Doppler'][k],v['reactor_parameters']['pu_content'][k]))\n",
    "print(len(temp_des))\n",
    "sm = tm.Surrogate_Models()\n",
    "sm.random=0\n",
    "sm.update_database(temp_des, temp_obj)\n",
    "model = 'lr'\n",
    "sm.update_model(model)\n",
    "sm.optimize_model(model)\n",
    "sm.predict(model, [[1.15,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter activation for estimator BayesSearchCV(cv=3, error_score='raise',\n              estimator=MLPRegressor(activation='logistic', alpha=0.0001,\n                                     batch_size='auto', beta_1=0.9,\n                                     beta_2=0.999, early_stopping=False,\n                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n                                     learning_rate='constant',\n                                     learning_rate_init=0.001, max_fun=15000,\n                                     max_iter=200, momentum=0.9,\n                                     n_iter_no_change=10,\n                                     nesterovs_momentum=True, power_t=0.5,\n                                     rand...\n              fit_params=None, iid=True, n_iter=50, n_jobs=16, n_points=1,\n              optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=0,\n              refit=True, return_train_score=False, scoring=None,\n              search_spaces={'activation': Categorical(categories=('tanh', 'relu', 'logistic'), prior=None),\n                             'hidden_layer_sizes': (2, 200, 'log-uniform'),\n                             'solver': Categorical(categories=('lbfgs', 'sgd'), prior=None)},\n              verbose=0). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/ryanstewart/Library/Python/3.7/lib/python/site-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter activation for estimator BayesSearchCV(cv=3, error_score='raise',\n              estimator=MLPRegressor(activation='logistic', alpha=0.0001,\n                                     batch_size='auto', beta_1=0.9,\n                                     beta_2=0.999, early_stopping=False,\n                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n                                     learning_rate='constant',\n                                     learning_rate_init=0.001, max_fun=15000,\n                                     max_iter=200, momentum=0.9,\n                                     n_iter_no_change=10,\n                                     nesterovs_momentum=True, power_t=0.5,\n                                     rand...\n              fit_params=None, iid=True, n_iter=50, n_jobs=16, n_points=1,\n              optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=0,\n              refit=True, return_train_score=False, scoring=None,\n              search_spaces={'activation': Categorical(categories=('tanh', 'relu', 'logistic'), prior=None),\n                             'hidden_layer_sizes': (2, 200, 'log-uniform'),\n                             'solver': Categorical(categories=('lbfgs', 'sgd'), prior=None)},\n              verbose=0). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9e19251fe15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ann'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m print(lvl_3['core_1.5111']['reactor_parameters']['keff']['core_1.5111'],lvl_3['core_1.5111']['reactor_parameters']['void']['core_1.5111'],\n\u001b[1;32m      5\u001b[0m       lvl_3['core_1.5111']['reactor_parameters']['Doppler']['core_1.5111'],lvl_3['core_1.5111']['reactor_parameters']['pu_content']['core_1.5111'])\n",
      "\u001b[0;32m~/projects/surrogate_modeling/src/train_surrogate_models.py\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(self, model_type, hp)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mhyper_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreturn_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/surrogate_modeling/src/train_surrogate_models.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model_type, hyper_parameters)\u001b[0m\n\u001b[1;32m    181\u001b[0m         hyper_model = BayesSearchCV(base_model, hyper_parameters, refit=True, n_jobs=16, \n\u001b[1;32m    182\u001b[0m                                     cv=self.cv, n_iter=self.number_iters, random_state=self.random)\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_var_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_obj_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mr2_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_var_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_obj_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mmse_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 optim_result = self._step(\n\u001b[1;32m    672\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 )\n\u001b[1;32m    675\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             )\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             for train, test in cv_iter)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter activation for estimator BayesSearchCV(cv=3, error_score='raise',\n              estimator=MLPRegressor(activation='logistic', alpha=0.0001,\n                                     batch_size='auto', beta_1=0.9,\n                                     beta_2=0.999, early_stopping=False,\n                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n                                     learning_rate='constant',\n                                     learning_rate_init=0.001, max_fun=15000,\n                                     max_iter=200, momentum=0.9,\n                                     n_iter_no_change=10,\n                                     nesterovs_momentum=True, power_t=0.5,\n                                     rand...\n              fit_params=None, iid=True, n_iter=50, n_jobs=16, n_points=1,\n              optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=0,\n              refit=True, return_train_score=False, scoring=None,\n              search_spaces={'activation': Categorical(categories=('tanh', 'relu', 'logistic'), prior=None),\n                             'hidden_layer_sizes': (2, 200, 'log-uniform'),\n                             'solver': Categorical(categories=('lbfgs', 'sgd'), prior=None)},\n              verbose=0). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "model = 'ann'\n",
    "sm.update_model(model)\n",
    "sm.optimize_model(model)\n",
    "print(lvl_3['core_1.5111']['reactor_parameters']['keff']['core_1.5111'],lvl_3['core_1.5111']['reactor_parameters']['void']['core_1.5111'],\n",
    "      lvl_3['core_1.5111']['reactor_parameters']['Doppler']['core_1.5111'],lvl_3['core_1.5111']['reactor_parameters']['pu_content']['core_1.5111'])\n",
    "print(sm.predict(model, [[1.15,1,1,1]]))\n",
    "print(sm.models[model]['mse_score'], sm.models[model]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.15,1,1,1\n",
    "104 - array([[   0.95067783, -142.97894534,   -0.75043104,    0.19088695]])\n",
    "94 - array([[   0.9458636 , -144.3811169 ,   -0.76500257,    0.21920749]])\n",
    "84 - array([[   0.93697795, -147.64010498,   -0.7750269 ,    0.19071838]])\n",
    "74 - array([[   0.92148437, -153.11656489,   -0.7958003 ,    0.16533378]])\n",
    "64 - array([[   0.9188606 , -153.81344203,   -0.80680371,    0.18924554]])\n",
    "54 - array([[   0.94344721, -145.17364131,   -0.77106811,    0.22301122]])\n",
    "44 - array([[   0.92699738, -150.78454251,   -0.79527818,    0.2197479 ]])\n",
    "34 - array([[   0.93131904, -149.41960065,   -0.7891247 ,    0.20827811]])\n",
    "5 - array([[   1.00889294, -121.2877934 ,   -0.67933475,    0.41458333]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
